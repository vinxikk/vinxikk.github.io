<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="YARN伪分布式&amp;WordCount案例&amp;jps命令&amp;OOM-kill机制和/tmp目录定时清理"><meta name="keywords" content="YARN伪分布式,WordCount案例,jps命令,OOM-kill机制,/tmp定时清理"><meta name="author" content="VinxC"><meta name="copyright" content="VinxC"><title>YARN伪分布式&amp;WordCount案例&amp;jps命令&amp;OOM-kill机制和/tmp目录定时清理 | VinxC's blog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#YARN伪分布式"><span class="toc-number">1.</span> <span class="toc-text">YARN伪分布式</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#伪分布式部署"><span class="toc-number">1.1.</span> <span class="toc-text">伪分布式部署</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#MR-wordcount案例"><span class="toc-number">2.</span> <span class="toc-text">MR wordcount案例</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#jps的真正使用"><span class="toc-number">3.</span> <span class="toc-text">jps的真正使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Linux的两个机制：OOM-Killer和-tmp目录定时清理"><span class="toc-number">4.</span> <span class="toc-text">Linux的两个机制：OOM-Killer和/tmp目录定时清理</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#OOM-Killer机制"><span class="toc-number">4.1.</span> <span class="toc-text">OOM-Killer机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#tmp自动清理机制"><span class="toc-number">4.2.</span> <span class="toc-text">/tmp自动清理机制</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://vinxikk.github.io/img/avatar.png"></div><div class="author-info__name text-center">VinxC</div><div class="author-info__description text-center">A Bigdata Developer</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">19</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">34</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">7</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" href="https://molunerfinn.com" target="_blank" rel="noopener">Molunerfinn</a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">VinxC's blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">YARN伪分布式&amp;WordCount案例&amp;jps命令&amp;OOM-kill机制和/tmp目录定时清理</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-03-30</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Hadoop/">Hadoop</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">1.6k</span><span class="post-meta__separator">|</span><span>Reading time: 7 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h3 id="YARN伪分布式"><a href="#YARN伪分布式" class="headerlink" title="YARN伪分布式"></a>YARN伪分布式</h3><p>官网：</p>
<p><a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html#YARN_on_a_Single_Node" target="_blank" rel="noopener">https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html#YARN_on_a_Single_Node</a></p>
<h4 id="伪分布式部署"><a href="#伪分布式部署" class="headerlink" title="伪分布式部署"></a>伪分布式部署</h4><ol>
<li><p>修改如下的配置文件：</p>
<p>etc/hadoop/mapred-site.xml:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></pre></td></tr></table></figure>

<p>etc/hadoop/yarn-site.xml:</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 默认yarn的端口号是8088，可以在此修改 --&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>hadoop001:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></pre></td></tr></table></figure>
</li>
<li><p>启动yarn：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">[vinx@hadoop001 hadoop]$ sbin/start-yarn.sh </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">[vinx@hadoop001 hadoop]$ jps</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">3908 Jps</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">3768 ResourceManager</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">3865 NodeManager</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">[vinx@hadoop001 hadoop]$ netstat -nlp | grep 3768</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">(Not all processes could be identified, non-owned process info</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line"> will not be shown, you would have to be root to see it all.)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">tcp        0      0 :::8030                     :::*                        LISTEN      3768/java           </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">tcp        0      0 :::8031                     :::*                        LISTEN      3768/java           </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">13</span></pre></td><td class="code"><pre><span class="line">tcp        0      0 :::8032                     :::*                        LISTEN      3768/java           </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">14</span></pre></td><td class="code"><pre><span class="line">tcp        0      0 :::8033                     :::*                        LISTEN      3768/java           </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">15</span></pre></td><td class="code"><pre><span class="line">tcp        0      0 ::ffff:192.168.xxx.xxx:8088 :::*                        LISTEN      3768/java</span></pre></td></tr></table></figure>

<p>可以看到YARN已经正常启动。</p>
</li>
<li><p>查看web界面：</p>
<p>ResourceManager - <a href="http://localhost:8088/" target="_blank" rel="noopener">http://localhost:8088/</a></p>
<p><img src="https://vinxikk.github.io/img/dw/yarn-web.png" alt="YARN的web界面"></p>
</li>
<li><p>运行一个MR作业</p>
</li>
<li><p>停止yarn：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">[vinx@hadoop001 hadoop]$ sbin/stop-yarn.sh</span></pre></td></tr></table></figure>

</li>
</ol>
<h3 id="MR-wordcount案例"><a href="#MR-wordcount案例" class="headerlink" title="MR wordcount案例"></a>MR wordcount案例</h3><p>wordcount是大数据领域的helloworld。</p>
<p>下面以Hadoop中的example jar演示wordcount案例。</p>
<p>数据准备：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">[vinx@hadoop001 hadoop]$ hdfs dfs -cat /wordcount/input/words.log</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">hello</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">world</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">hello</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">hadoop</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">hello spark</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">hello flink</span></pre></td></tr></table></figure>

<p>当前路径：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">[vinx@hadoop001 hadoop]$ <span class="built_in">pwd</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">/home/vinx/app/hadoop</span></pre></td></tr></table></figure>

<p>查找名称中有example的jar包：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">[vinx@hadoop001 hadoop]$ find ./ -name <span class="string">'*example*.jar'</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">./share/hadoop/mapreduce1/hadoop-examples-2.6.0-mr1-cdh5.16.2.jar</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">./share/hadoop/mapreduce2/sources/hadoop-mapreduce-examples-2.6.0-cdh5.16.2-test-sources.jar</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">./share/hadoop/mapreduce2/sources/hadoop-mapreduce-examples-2.6.0-cdh5.16.2-sources.jar</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">./share/hadoop/mapreduce2/hadoop-mapreduce-examples-2.6.0-cdh5.16.2.jar  选用这个jar包</span></pre></td></tr></table></figure>

<p>启动hdfs和yarn：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">[vinx@hadoop001 hadoop]$ sbin/start-dfs.sh</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">[vinx@hadoop001 hadoop]$ sbin/start-yarn.sh</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">[vinx@hadoop001 hadoop]$ jps</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">4678 SecondaryNameNode</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">4791 Jps</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">3768 ResourceManager</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">3865 NodeManager</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">4378 NameNode</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">4511 DataNode</span></pre></td></tr></table></figure>

<p>运行wordcount程序：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">[vinx@hadoop001 hadoop]$ hadoop \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">&gt; jar /home/vinx/app/hadoop/share/hadoop/mapreduce2/hadoop-mapreduce-examples-2.6.0-cdh5.16.2.jar \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">&gt; wordcount \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">&gt; /wordcount/input \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">&gt; /wordcount/output02</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">命令解释：</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">hadoop \           需要加\换行</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">jar /home/vinx/app/hadoop/share/hadoop/mapreduce2/hadoop-mapreduce-examples-2.6.0-cdh5.16.2.jar \        使用的jar包</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">wordcount \            使用的主类</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">/wordcount/input \     输入数据 </span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">/wordcount/output02    输出路径</span></pre></td></tr></table></figure>

<p>程序运行成功：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">18/03/10 20:31:29 INFO mapreduce.Job: Running job: job_1575979215182_0001</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">18/03/10 20:31:43 INFO mapreduce.Job: Job job_1575979215182_0001 running <span class="keyword">in</span> uber mode : <span class="literal">false</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">18/03/10 20:31:43 INFO mapreduce.Job:  map 0% reduce 0%</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">18/03/10 20:31:50 INFO mapreduce.Job:  map 100% reduce 0%</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">18/03/10 20:31:57 INFO mapreduce.Job:  map 100% reduce 100%</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">18/03/10 20:31:58 INFO mapreduce.Job: Job job_1575979215182_0001 completed successfully</span></pre></td></tr></table></figure>

<p>查看程序计算结果：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">[vinx@hadoop001 hadoop]$ hadoop fs -cat /wordcount/output02/part-r-00000</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">flink	1</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">hadoop	1</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">hello	4</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">spark	1</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">world	1</span></pre></td></tr></table></figure>

<h3 id="jps的真正使用"><a href="#jps的真正使用" class="headerlink" title="jps的真正使用"></a>jps的真正使用</h3><p>查看jps的位置：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">[vinx@hadoop001 hadoop]$ <span class="built_in">which</span> jps</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">/usr/java/jdk1.8.0_45/bin/jps</span></pre></td></tr></table></figure>

<p>查看jps命令帮助：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">[vinx@hadoop001 hadoop]$ jps -<span class="built_in">help</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">usage: jps [-<span class="built_in">help</span>]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">       jps [-q] [-mlvV] [&lt;hostid&gt;]</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">Definitions:</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">    &lt;hostid&gt;:      &lt;hostname&gt;[:&lt;port&gt;]</span></pre></td></tr></table></figure>

<p>jps查看详细进程信息：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">[vinx@hadoop001 hadoop]$ jps -l</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">4678 org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">3768 org.apache.hadoop.yarn.server.resourcemanager.ResourceManager</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">3865 org.apache.hadoop.yarn.server.nodemanager.NodeManager</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">4378 org.apache.hadoop.hdfs.server.namenode.NameNode</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">8077 sun.tools.jps.Jps</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">4511 org.apache.hadoop.hdfs.server.datanode.DataNode</span></pre></td></tr></table></figure>

<p>查看相应进程的文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">[root@hadoop001 hsperfdata_vinx]<span class="comment"># pwd</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">/tmp/hsperfdata_vinx</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">[root@hadoop001 hsperfdata_vinx]<span class="comment"># ll</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">total 160</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">-rw-------. 1 vinx vinx 32768 Dec 10 20:57 3768</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">-rw-------. 1 vinx vinx 32768 Dec 10 20:57 3865</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">-rw-------. 1 vinx vinx 32768 Dec 10 20:57 4378</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">-rw-------. 1 vinx vinx 32768 Dec 10 20:57 4511</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">-rw-------. 1 vinx vinx 32768 Dec 10 20:57 4678</span></pre></td></tr></table></figure>

<p>root用户下使用jps命令查看当前进程：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">[root@hadoop001 hsperfdata_vinx]<span class="comment"># jps</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">4678 -- process information unavailable</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">3768 -- process information unavailable</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">3865 -- process information unavailable</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">4378 -- process information unavailable</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">8124 Jps</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">4511 -- process information unavailable</span></pre></td></tr></table></figure>

<p>可以看到，如果是进程所属的用户vinx去执行jps命令，只会显示当前用户相关的进程信息。</p>
<p>而root用户可以看所有的进程信息，但是不是root用户启动的进程，会显示process information unavailable。</p>
<p>当root用户执行jps命令后，显示process information unavailable时，我们如果确定进程是否存在呢？可以使用下面的命令查看相关进程的详细信息，比如查看进程4678的信息：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">会显示当前命令的进程，总共2个进程</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">[root@hadoop001 hsperfdata_vinx]<span class="comment"># ps -ef | grep 4678</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">过滤自己</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">[root@hadoop001 hsperfdata_vinx]<span class="comment"># ps -ef | grep 4678 | grep -v grep</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line"></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">进程数</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">[root@hadoop001 hsperfdata_vinx]<span class="comment"># ps -ef | grep 4678 | grep -v grep | wc -l</span></span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">1</span></pre></td></tr></table></figure>

<h3 id="Linux的两个机制：OOM-Killer和-tmp目录定时清理"><a href="#Linux的两个机制：OOM-Killer和-tmp目录定时清理" class="headerlink" title="Linux的两个机制：OOM-Killer和/tmp目录定时清理"></a>Linux的两个机制：OOM-Killer和/tmp目录定时清理</h3><h4 id="OOM-Killer机制"><a href="#OOM-Killer机制" class="headerlink" title="OOM-Killer机制"></a>OOM-Killer机制</h4><p>OOM Killer的全称为Out of Memory (OOM) killer，它的作用简单点说就是，当系统的内存用光的时候，系统内核会自动的Kill掉一个或者一些进程，以使系统能继续的恢复到正常的运行状态。</p>
<p>查看机器的内存情况：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">free -m</span></pre></td></tr></table></figure>

<p>OOM Killer每一次Kill掉进程都会在messages日志里留下记录，检查的命令为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">cat /var/<span class="built_in">log</span>/messages | grep oom</span></pre></td></tr></table></figure>

<p>部分系统时中日志里的关键字为：Out of memory，对应的检查命令为：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">cat /var/<span class="built_in">log</span>/messages | grep -i <span class="string">'Out of memory'</span></span></pre></td></tr></table></figure>

<p>如果日志里频繁的出现OOM记录，那么就需要考虑调整服务器配置了（软件或者硬件）。</p>
<p>解决办法：</p>
<ol>
<li>限制java进程的max heap，从而降低内存使用</li>
<li>发现系统没有开启swap，给系统加swap空间（内存数x2）</li>
</ol>
<h4 id="tmp自动清理机制"><a href="#tmp自动清理机制" class="headerlink" title="/tmp自动清理机制"></a>/tmp自动清理机制</h4><p>在Linux系统中/tmp文件夹里是存放临时文件的，/tmp默认存储周期 30天，会自动清空不在规则以内的文件。</p>
<p>/etc/cron.daily/tmpwatch这个文件的作用就是删除/tmp目录下不在规则内且没有访问的文件文件夹，文件内容如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">[root@hadoop001 ~]# cat &#x2F;etc&#x2F;cron.daily&#x2F;tmpwatch</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">#! &#x2F;bin&#x2F;sh</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">flags&#x3D;-umc</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">&#x2F;usr&#x2F;sbin&#x2F;tmpwatch &quot;$flags&quot; -x &#x2F;tmp&#x2F;.X11-unix -x &#x2F;tmp&#x2F;.XIM-unix \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">	-x &#x2F;tmp&#x2F;.font-unix -x &#x2F;tmp&#x2F;.ICE-unix -x &#x2F;tmp&#x2F;.Test-unix \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">6</span></pre></td><td class="code"><pre><span class="line">	-X &#39;&#x2F;tmp&#x2F;hsperfdata_*&#39; 10d &#x2F;tmp</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">7</span></pre></td><td class="code"><pre><span class="line">&#x2F;usr&#x2F;sbin&#x2F;tmpwatch &quot;$flags&quot; 30d &#x2F;var&#x2F;tmp</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">8</span></pre></td><td class="code"><pre><span class="line">for d in &#x2F;var&#x2F;&#123;cache&#x2F;man,catman&#125;&#x2F;&#123;cat?,X11R6&#x2F;cat?,local&#x2F;cat?&#125;; do</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">9</span></pre></td><td class="code"><pre><span class="line">    if [ -d &quot;$d&quot; ]; then</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">10</span></pre></td><td class="code"><pre><span class="line">	&#x2F;usr&#x2F;sbin&#x2F;tmpwatch &quot;$flags&quot; -f 30d &quot;$d&quot;</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">11</span></pre></td><td class="code"><pre><span class="line">    fi</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">12</span></pre></td><td class="code"><pre><span class="line">done</span></pre></td></tr></table></figure>

<p>解释：</p>
<p>/usr/sbin/tmpwatch “$flags” 30d /var/tmp这一行的30d就决定了30天清理/tmp下不访问的文件。如果你想一天一清理的话，就把这个30d改成1d。</p>
<p>但有个问题要注意，如果你设置更短的时间来清理的话，比如说30分钟、10秒等，重启系统后你会发现设置无效，这是因为tmpwatch的上层目录是/etc/cron.daily/，而这个目录是一天执行一次计划任务，所以说，你设置了比一天更短的时间，他就不起作用了。</p>
<p>在Centos6中，系统自动清理/tmp文件夹的默认时限是30天</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined" target="_blank" rel="noopener">VinxC</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="/https:/vinxikk.github.io/2018/03/30/dw/hadoop-2/">https://vinxikk.github.io/2018/03/30/dw/hadoop-2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/YARN%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F/">YARN伪分布式</a><a class="post-meta__tags" href="/tags/WordCount%E6%A1%88%E4%BE%8B/">WordCount案例</a><a class="post-meta__tags" href="/tags/jps%E5%91%BD%E4%BB%A4/">jps命令</a><a class="post-meta__tags" href="/tags/OOM-kill%E6%9C%BA%E5%88%B6/">OOM-kill机制</a><a class="post-meta__tags" href="/tags/tmp%E5%AE%9A%E6%97%B6%E6%B8%85%E7%90%86/">/tmp定时清理</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2018/04/01/dw/hadoop-3/"><i class="fa fa-chevron-left">  </i><span>HDFS架构&amp;NameNode和DataNode工作机制&amp;BLOCK和副本数&amp;小文件问题</span></a></div><div class="next-post pull-right"><a href="/2018/03/27/dw/hadoop-1/"><span>HDFS伪分布式&amp;HDFS常用命令</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2019 By VinxC</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script src="/js/search/local-search.js"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>