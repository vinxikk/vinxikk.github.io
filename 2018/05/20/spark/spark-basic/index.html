<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="description" content="Spark架构和部署&amp;WordCount原理"><meta name="keywords" content="Spark"><meta name="author" content="VinxC"><meta name="copyright" content="VinxC"><title>Spark架构和部署&amp;WordCount原理 | VinxC's blog</title><link rel="shortcut icon" href="/melody-favicon.ico"><link rel="stylesheet" href="/css/index.css?version=1.6.1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css?version=1.6.1"><link rel="dns-prefetch" href="https://cdn.staticfile.org"><link rel="dns-prefetch" href="https://cdn.bootcss.com"><link rel="dns-prefetch" href="https://creativecommons.org"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  }
} </script></head><body><canvas class="fireworks"></canvas><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true"></i><div id="sidebar"><div class="toggle-sidebar-info text-center"><span data-toggle="Toggle article">Toggle site</span><hr></div><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar"></div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#什么是Spark"><span class="toc-number">1.</span> <span class="toc-text">什么是Spark</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark的架构"><span class="toc-number">2.</span> <span class="toc-text">Spark的架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark部署"><span class="toc-number">3.</span> <span class="toc-text">Spark部署</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Spark-Standalone伪分布式部署"><span class="toc-number">3.1.</span> <span class="toc-text">Spark Standalone伪分布式部署</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Spark-Standalone全分布式部署"><span class="toc-number">3.2.</span> <span class="toc-text">Spark Standalone全分布式部署</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark-Demo"><span class="toc-number">4.</span> <span class="toc-text">Spark Demo</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Spark-Example"><span class="toc-number">4.1.</span> <span class="toc-text">Spark Example</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#使用Spark-Shell"><span class="toc-number">4.2.</span> <span class="toc-text">使用Spark Shell</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Spark运行机制"><span class="toc-number">5.</span> <span class="toc-text">Spark运行机制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#WordCount执行的流程"><span class="toc-number">5.1.</span> <span class="toc-text">WordCount执行的流程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Spark提交任务的流程"><span class="toc-number">5.2.</span> <span class="toc-text">Spark提交任务的流程</span></a></li></ol></li></ol></div></div><div class="author-info hide"><div class="author-info__avatar text-center"><img src="https://vinxikk.github.io/img/avatar.png"></div><div class="author-info__name text-center">VinxC</div><div class="author-info__description text-center">A Bigdata Developer</div><hr><div class="author-info-articles"><a class="author-info-articles__archives article-meta" href="/archives"><span class="pull-left">Articles</span><span class="pull-right">72</span></a><a class="author-info-articles__tags article-meta" href="/tags"><span class="pull-left">Tags</span><span class="pull-right">89</span></a><a class="author-info-articles__categories article-meta" href="/categories"><span class="pull-left">Categories</span><span class="pull-right">15</span></a></div><hr><div class="author-info-links"><div class="author-info-links__title text-center">Links</div><a class="author-info-links__name text-center" href="https://molunerfinn.com" target="_blank" rel="noopener">Molunerfinn</a></div></div></div><div id="content-outer"><div class="no-bg" id="top-container"><div id="page-header"><span class="pull-left"> <a id="site-name" href="/">VinxC's blog</a></span><i class="fa fa-bars toggle-menu pull-right" aria-hidden="true"></i><span class="pull-right menus"><a class="site-page social-icon search"><i class="fa fa-search"></i><span> Search</span></a><a class="site-page" href="/">Home</a><a class="site-page" href="/archives">Archives</a><a class="site-page" href="/tags">Tags</a><a class="site-page" href="/categories">Categories</a></span></div><div id="post-info"><div id="post-title">Spark架构和部署&amp;WordCount原理</div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar" aria-hidden="true"></i> 2018-05-20</time><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/Spark/">Spark</a><div class="post-meta-wordcount"><span>Word count: </span><span class="word-count">712</span><span class="post-meta__separator">|</span><span>Reading time: 2 min</span></div></div></div></div><div class="layout" id="content-inner"><article id="post"><div class="article-container" id="post-content"><h3 id="什么是Spark"><a href="#什么是Spark" class="headerlink" title="什么是Spark"></a>什么是Spark</h3><p>Spark官网：</p>
<p><a href="http://spark.apache.org/" target="_blank" rel="noopener">http://spark.apache.org/</a></p>
<p><img src="https://vinxikk.github.io/img/spark/what-is-spark.png" alt="Spark是什么"></p>
<p>Spark是一个针对大规模数据处理的快速通用引擎。</p>
<p>Spark是一种快速、通用、可扩展的大数据分析引擎，2009年诞生于加州大学伯克利分校AMPLab，2010年开源，2013年6月成为Apache孵化项目，2014年2月成为Apache顶级项目。目前，Spark生态系统已经发展成为一个包含多个子项目的集合，其中包含SparkSQL、Spark Streaming、GraphX、MLlib等子项目，Spark是基于内存计算的大数据并行计算框架。Spark基于内存计算，提高了在大数据环境下数据处理的实时性，同时保证了高容错性和高可伸缩性，允许用户将Spark部署在大量廉价硬件之上，形成集群。</p>
<h3 id="Spark的架构"><a href="#Spark的架构" class="headerlink" title="Spark的架构"></a>Spark的架构</h3><p><img src="https://vinxikk.github.io/img/spark/spark-cluster-architecture.png" alt="Spark集群架构"></p>
<p><img src="https://vinxikk.github.io/img/spark/spark-master-worker.png" alt="Spark主从结构"></p>
<h3 id="Spark部署"><a href="#Spark部署" class="headerlink" title="Spark部署"></a>Spark部署</h3><p>Spark的部署有以下几种模式：</p>
<ul>
<li>Standalone</li>
<li>YARN</li>
<li>Mesos</li>
<li>Amason EC2</li>
</ul>
<h4 id="Spark-Standalone伪分布式部署"><a href="#Spark-Standalone伪分布式部署" class="headerlink" title="Spark Standalone伪分布式部署"></a>Spark Standalone伪分布式部署</h4><p>配置文件con/spark-env.sh：</p>
<p><code>export JAVA_HOME=/usr/java/jdk1.8.0_121</code></p>
<p><code>export SPARK_MASTER_HOST=rshost001</code></p>
<p><code>export SPARK_MASTER_PORT=7077</code></p>
<p>下面的可以不写，默认<br><code>export SPARK_WORKER_CORES=1</code><br><code>export SPARK_WORKER_MEMORY=1024m</code></p>
<p>配置文件conf/slave：</p>
<p><code>rshost001</code></p>
<h4 id="Spark-Standalone全分布式部署"><a href="#Spark-Standalone全分布式部署" class="headerlink" title="Spark Standalone全分布式部署"></a>Spark Standalone全分布式部署</h4><p>配置文件con/spark-env.sh：</p>
<p><code>export JAVA_HOME=/usr/java/jdk1.8.0_121</code></p>
<p><code>export SPARK_MASTER_HOST=rshost001</code></p>
<p><code>export SPARK_MASTER_PORT=7077</code></p>
<p>下面的可以不写，默认<br><code>export SPARK_WORKER_CORES=1</code><br><code>export SPARK_WORKER_MEMORY=1024m</code></p>
<p>配置文件conf/slave：</p>
<p><code>rshost002</code></p>
<p><code>rshost001</code></p>
<p>启动Spark集群：<code>start-all.sh</code></p>
<p>Web UI界面：<a href="http://rshost001:8080/" target="_blank" rel="noopener">http://rshost001:8080/</a></p>
<h3 id="Spark-Demo"><a href="#Spark-Demo" class="headerlink" title="Spark Demo"></a>Spark Demo</h3><h4 id="Spark-Example"><a href="#Spark-Example" class="headerlink" title="Spark Example"></a>Spark Example</h4><p>示例jar包路径：<code>$SPARK_HOME/examples/jars/spark-examples_2.11-2.1.0.jar</code></p>
<p>示例程序源码：<code>$SPARK_HOME/examples/src/main</code></p>
<p>Demo蒙特卡洛求PI：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">./bin/spark-submit \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">--master spark://rshost001:7077 \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">--class org.apache.spark.examples.SparkPi \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">/home/vinx/app/spark-2.1.1-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.1.1.jar \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">100</span></pre></td></tr></table></figure>

<h4 id="使用Spark-Shell"><a href="#使用Spark-Shell" class="headerlink" title="使用Spark Shell"></a>使用Spark Shell</h4><p>spark-shell是Spark自带的交互式Shell程序，方便用户进行交互式编程，用户可以在该命令行下用scala编写spark程序。</p>
<p>启动spark shell：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">./bin/spark-shell \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">--master spark://rshost001:7077 \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">--executor-memory 2g \</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">--total-executor-cores 1</span></pre></td></tr></table></figure>

<p>参数说明：<br><code>--master spark://rshost001:7077</code> 指定Master的地址<br><code>--executor-memory 2g</code> 指定每个worker可用内存为2G<br><code>--total-executor-cores 1</code> 指定整个集群使用的cup核数为1个</p>
<p>如果启动spark shell时没有指定master地址，但是也可以正常启动spark shell和执行spark shell中的程序，其实是启动了spark的local模式，该模式仅在本机启动一个进程，没有与集群建立联系。</p>
<p>在Spark Shell中编写WordCount程序：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span></pre></td><td class="code"><pre><span class="line">sc.textFile(<span class="string">"/home/vinx/data/words.txt"</span>)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">2</span></pre></td><td class="code"><pre><span class="line">.flatMap(_.split(<span class="string">" "</span>))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">3</span></pre></td><td class="code"><pre><span class="line">.map((_,<span class="number">1</span>))</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">4</span></pre></td><td class="code"><pre><span class="line">.reduceByKey(_+_)</span></pre></td></tr><tr><td class="gutter"><pre><span class="line">5</span></pre></td><td class="code"><pre><span class="line">.saveAsTextFile(<span class="string">"/home/vinx/data/wordcount"</span>)</span></pre></td></tr></table></figure>

<p>说明：<br>sc是SparkContext对象，该对象是提交spark程序的入口<br><code>textFile(&quot;/home/vinx/data/words.txt&quot;)</code>读取本地数据<br><code>flatMap(_.split(&quot; &quot;))</code> 先map再压平<br><code>map((_,1))</code> 将单词和1构成元组<br><code>reduceByKey(_+_)</code> 按照key进行reduce，并将value累加<br><code>saveAsTextFile(&quot;/home/vinx/data/wordcount&quot;)</code>将结果写入到本地目录</p>
<h3 id="Spark运行机制"><a href="#Spark运行机制" class="headerlink" title="Spark运行机制"></a>Spark运行机制</h3><h4 id="WordCount执行的流程"><a href="#WordCount执行的流程" class="headerlink" title="WordCount执行的流程"></a>WordCount执行的流程</h4><p><img src="https://vinxikk.github.io/img/spark/spark-wordcount.png" alt="WordCount执行过程"></p>
<h4 id="Spark提交任务的流程"><a href="#Spark提交任务的流程" class="headerlink" title="Spark提交任务的流程"></a>Spark提交任务的流程</h4><p><img src="https://vinxikk.github.io/img/spark/spark-job.png" alt="Spark任务提交过程"></p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined" target="_blank" rel="noopener">VinxC</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="/https:/vinxikk.github.io/2018/05/20/spark/spark-basic/">https://vinxikk.github.io/2018/05/20/spark/spark-basic/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Spark/">Spark</a></div><nav id="pagination"><div class="prev-post pull-left"><a href="/2018/05/21/spark/spark-high-level-operation/"><i class="fa fa-chevron-left">  </i><span>RDD高级算子</span></a></div><div class="next-post pull-right"><a href="/2018/05/19/spark/spark-core/"><span>RDD的常用算子&amp;persist/cache缓存机制&amp;checkpoint容错机制</span><i class="fa fa-chevron-right"></i></a></div></nav></div></div><footer><div class="layout" id="footer"><div class="copyright">&copy;2017 - 2020 By VinxC</div><div class="framework-info"><span>Driven - </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>Theme - </span><a href="https://github.com/Molunerfinn/hexo-theme-melody" target="_blank" rel="noopener"><span>Melody</span></a></div><div class="busuanzi"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><span id="busuanzi_container_page_pv"><i class="fa fa-file-o"></i><span id="busuanzi_value_page_pv"></span><span></span></span></div></div></footer><i class="fa fa-arrow-up" id="go-up" aria-hidden="true"></i><script src="https://cdn.jsdelivr.net/npm/animejs@latest/anime.min.js"></script><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-animate@latest/velocity.min.js"></script><script src="https://cdn.jsdelivr.net/npm/velocity-ui-pack@latest/velocity.ui.min.js"></script><script src="/js/utils.js?version=1.6.1"></script><script src="/js/fancybox.js?version=1.6.1"></script><script src="/js/sidebar.js?version=1.6.1"></script><script src="/js/copy.js?version=1.6.1"></script><script src="/js/fireworks.js?version=1.6.1"></script><script src="/js/transition.js?version=1.6.1"></script><script src="/js/scroll.js?version=1.6.1"></script><script src="/js/head.js?version=1.6.1"></script><script src="/js/search/local-search.js"></script><script>if(/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) {
  $('#nav').addClass('is-mobile')
  $('footer').addClass('is-mobile')
}</script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">Local search</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>Powered by</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>